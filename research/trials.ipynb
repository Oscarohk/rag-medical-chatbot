{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff903a1",
   "metadata": {},
   "source": [
    "# Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5077679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ohokin\\anaconda3\\envs\\medibot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text fom PDF files\n",
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(\n",
    "        path=data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ababf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "extracted_data = load_pdf_files(\"./data\")\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69922ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d21d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects containing only 'source' in metadata \n",
    "    and the original page_content \n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8db8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)\n",
    "minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3969fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(minimal_docs):\n",
    "    \"\"\"\n",
    "    Given a list of documents, split them into smaller chunks of text.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(minimal_docs)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8df6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(minimal_docs)\n",
    "print(f\"Number of chunks: {len(text_chunks)}\")\n",
    "text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534912e0",
   "metadata": {},
   "source": [
    "# Embedding and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75b1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = \"E:/ohokin/.cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b3a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ohokin\\AppData\\Local\\Temp\\ipykernel_22916\\343875959.py:8: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings_model = HuggingFaceBgeEmbeddings(\n",
      "e:\\ohokin\\anaconda3\\envs\\medibot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "def download_embeddings_model():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings_model\n",
    "\n",
    "embeddings_model = download_embeddings_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ed48e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceBgeEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_instruction='Represent this question for searching relevant passages: ', embed_instruction='', show_progress=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db302d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embeddings_model.embed_query(\"Hello World\")\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9866c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a670c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366dd10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x29f033edae0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a57570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"medibot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,      # Dimension of the embeddings\n",
    "        metric=\"cosine\",    # Cosine Similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings_model,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4eb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"medibot\"\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac520027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more data to existing Pinecone Index\n",
    "\n",
    "dswith = Document(\n",
    "    page_content=\"random stuff\",\n",
    "    metadata={\"source\": \"N/A\"}\n",
    ")\n",
    "docsearch.add_documents(documents=[dswith])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4dc3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efbabdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1e9504b4-fc83-43d6-a51f-1e652ba5878a', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='9e1ec9f9-dd0f-4fcc-bb74-051c3f961a59', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='d7ca7342-c64f-44bc-87d5-103c6f3d7bab', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='Cliffs, NJ: Prentice Hall, 1995.\\nGoldstein, Sanford M., and Richard B. Odom. “Skin &\\nAppendages: Pustular Disorders.” In Current Medical\\nDiagnosis and Treatment, 1996.35th ed. Ed. Stephen\\nMcPhee, et al. Stamford: Appleton & Lange, 1995.\\nKaptchuk, Ted J., Z’ev Rosenberg, and K’an Herb Co., Inc.\\nK’an Herbals: Formulas by Ted Kaptchuk, O.M.D.San\\nFrancisco: Andrew Miller, 1996.\\nPERIODICALS\\n“Adult Acne.”Harvard Women’s Health Watch(Mar. 1995): 4-\\n5.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5492b",
   "metadata": {},
   "source": [
    "# RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec47251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    "    provider=\"auto\",  # let Hugging Face choose the best provider for you\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef01523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb5be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a medical assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40766ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(chat_model, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58486450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly and gigantism are two disorders that occur when the pituitary gland releases too much of a hormone called growth hormone (GH). Growth hormone is produced by the pituitary gland and plays a role in growth and development during childhood and adolescence. \n",
      "\n",
      "In acromegaly, the excess growth hormone causes excessive growth and enlargement of body parts, such as the hands, feet, fingers, toes, and face, as well as other tissues. In gigantism, the excess growth hormone causes excessive growth and enlargement of body parts during childhood and adolescence, often before the age of 15.\n",
      "\n",
      "Both conditions are rare and can cause a range of symptoms, including:\n",
      "\n",
      "* Enlarged hands, feet, and face\n",
      "* Excessive sweating\n",
      "* High blood pressure\n",
      "* Heart problems\n",
      "* Vision problems\n",
      "* Bone fractures\n",
      "* Decreased fertility in men\n",
      "\n",
      "Acromegaly is a hormone disorder caused by a non-cancerous (benign) tumor on the pituitary gland, while gigantism is a rare congenital disorder caused by a genetic mutation that affects the growth hormone production.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
